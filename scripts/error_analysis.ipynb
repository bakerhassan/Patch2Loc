{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/lustre/scratch/bakerh/cvpr/patch2loc_t1/checkpoints/last_fold-{fold}.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/job_30088952/step_0.0/ipykernel_59883/406273352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPatch2Loc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/lightning/pytorch/utilities/model_helpers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0;34m\" Please call it on the class type and make sure the return value is used.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 )\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/lightning/pytorch/core/module.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \"\"\"\n\u001b[0;32m-> 1582\u001b[0;31m         loaded = _load_from_checkpoint(\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/lightning/pytorch/core/saving.py\u001b[0m in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_default_map_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpl_legacy_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# convert legacy checkpoints to the new format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/lightning/fabric/utilities/cloud_io.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location, weights_only)\u001b[0m\n\u001b[1;32m     57\u001b[0m         )\n\u001b[1;32m     58\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         return torch.load(\n\u001b[1;32m     61\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"autocommit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m             f = self._open(\n\u001b[0m\u001b[1;32m   1302\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_mkdir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLocalFileOpener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtouch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0mcompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/lustre/scratch/bakerh/cvpr/patch2loc_t1/checkpoints/last_fold-{fold}.ckpt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "os.chdir(\"/lustre/scratch/bakerh/cvpr/CVPR2025/\") \n",
    "\n",
    "from src.datamodules.Datamodules_eval import Brats21\n",
    "from src.datamodules.Datamodules_train import IXI\n",
    "from src.models.patch2loc_model import Patch2Loc\n",
    "\n",
    "            \n",
    "def remove_underscore_keys(d):\n",
    "    return {k: v for k, v in d.items() if not k.startswith(\"_\")}\n",
    "\n",
    "fold = 1\n",
    "# ckpt_path = f'/lustre/scratch/bakerh/cvpr/patch2loc_t2_single_scale/checkpoints/last_fold-{fold}.ckpt'\n",
    "ckpt_path = f'/lustre/scratch/bakerh/cvpr/patch2loc_t1/checkpoints/last_fold-{fold}.ckpt'\n",
    "with open(\"./configs/datamodule/IXI.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "config = remove_underscore_keys(config)\n",
    "config = config['cfg']\n",
    "config['mode'] = 't1'\n",
    "config['data_dir'] = '/lustre/scratch/bakerh/cvpr/data/Data/'\n",
    "config['sample_set'] = True\n",
    "config['num_workers'] = 0\n",
    "config['rescaleFactor'] = 1\n",
    "config['imageDim'] = [192,192,100]\n",
    "config['num_folds'] = fold\n",
    "\n",
    "config = OmegaConf.create(config)\n",
    "config = OmegaConf.create(OmegaConf.to_container(config, resolve=True))\n",
    "lightningDataModule = Brats21(config)\n",
    "# lightningDataModule = IXI(config,1)\n",
    "\n",
    "lightningDataModule.setup()\n",
    "dataloader = lightningDataModule.test_dataloader()\n",
    "# dataloader = lightningDataModule.val_eval_dataloader()\n",
    "\n",
    "# Ensure the output folder exists\n",
    "output_folder = 'notebook_figures'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "self = Patch2Loc.load_from_checkpoint(ckpt_path, strict=False)\n",
    "self.on_test_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import  extract_volume_patches\n",
    "import torchio as tio\n",
    "\n",
    "from skimage import exposure\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import equalize\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib\n",
    "\n",
    "def plot_images(input_images, final_volumes, brain_masks, num_rows=5):\n",
    "    \"\"\"\n",
    "    Plots rotated input images, final volumes (heatmaps with jet colormap), \n",
    "    and brain masks using make_grid.\n",
    "\n",
    "    Parameters:\n",
    "        input_images (Tensor): (N, 1, H, W)\n",
    "        final_volumes (Tensor): (N, 1, H, W)\n",
    "        brain_masks (Tensor): (N, 1, H, W)\n",
    "        num_rows (int): Number of images to plot (default: 30)\n",
    "    \"\"\"    \n",
    "    # Select subset and rotate\n",
    "    def preprocess(tensor_batch):\n",
    "        return torch.stack([\n",
    "            torch.rot90(tensor.squeeze(0), k=3, dims=(0, 1)) for tensor in tensor_batch[num_rows-1::num_rows]\n",
    "        ])\n",
    "    \n",
    "    input_rot = preprocess(input_images)\n",
    "    heatmap_rot = preprocess(final_volumes)\n",
    "    mask_rot = preprocess(brain_masks)\n",
    "    num_rows = input_rot.shape[0]\n",
    "    # Normalize heatmaps to [0, 1] based on robust quantiles\n",
    "    qmin = torch.quantile(heatmap_rot[heatmap_rot > 0], 0.01).item()\n",
    "    qmax = torch.quantile(heatmap_rot[heatmap_rot > 0], 0.99).item()\n",
    "    heatmap_norm = (heatmap_rot - qmin) / (qmax - qmin)\n",
    "    heatmap_norm = torch.clamp(heatmap_norm, 0, 1)\n",
    "\n",
    "    # Apply jet colormap to heatmaps\n",
    "    jet_cmap = matplotlib.colormaps.get_cmap('jet')\n",
    "    heatmap_rgb = torch.tensor(jet_cmap(heatmap_norm.numpy())[:, :, :, :3])  # (N, H, W, 3)\n",
    "    heatmap_rgb = heatmap_rgb.permute(0, 3, 1, 2).float()  # (N, 3, H, W)\n",
    "\n",
    "    # Convert grayscale to 3 channels\n",
    "    def gray_to_rgb(tensor):\n",
    "        return tensor.unsqueeze(1).repeat(1, 3, 1, 1).float()\n",
    "\n",
    "    input_rgb = gray_to_rgb(input_rot)\n",
    "    mask_rgb = gray_to_rgb(mask_rot)\n",
    "\n",
    "    # Make a grid for each set\n",
    "    input_grid = vutils.make_grid(input_rgb, nrow=num_rows, padding=2)\n",
    "    heatmap_grid = vutils.make_grid(heatmap_rgb, nrow=num_rows, padding=2)\n",
    "    mask_grid = vutils.make_grid(mask_rgb, nrow=num_rows, padding=2)\n",
    "    input_grid = torch.clamp(input_grid, 0, torch.quantile(input_grid,.99).item())\n",
    "    # Concatenate grids vertically\n",
    "    full_grid = torch.cat([input_grid, heatmap_grid, mask_grid], dim=1)\n",
    "\n",
    "    # Display using matplotlib\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.imshow(full_grid.permute(1, 2, 0).cpu().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Input | Heatmap (jet) | Mask\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def get_voxel_quantile_ranks(image, quantiles_path):\n",
    "    \"\"\"\n",
    "    Given a 3D image, determines the voxel-wise quantile rank using a precomputed quantile function.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Input 3D image of shape (C, H, W) with intensity values.\n",
    "        quantiles_path (str): Path to the saved quantile function (Q, C, H, W).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor of shape (C, H, W) containing the quantile rank (0 to 1) for each voxel.\n",
    "    \"\"\"\n",
    "    # Load the precomputed quantile function (Q, C, H, W)\n",
    "    quantiles = torch.load(quantiles_path).permute(0,2,3,1) # Shape: (Q, C, H, W)\n",
    "    Q, C, H, W = quantiles.shape  # Q = number of quantiles\n",
    "\n",
    "    # Ensure the input image shape matches (C, H, W)\n",
    "    assert image.shape == (C, H, W), f\"Image shape {image.shape} must match (C, H, W) of quantiles\"\n",
    "\n",
    "    # Reshape quantiles to (C*H*W, Q) so each voxel gets its own sorted quantile distribution\n",
    "    quantiles = quantiles.permute(1, 2, 3, 0).reshape(-1, Q)  # Shape: (C*H*W, Q)\n",
    "\n",
    "    # Flatten image to (C*H*W)\n",
    "    image = image.flatten()  # Shape: (C*H*W,)\n",
    "\n",
    "    # Find where each voxel value falls in the quantile distribution\n",
    "    quantile_indices = torch.searchsorted(quantiles, image.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    # Normalize the quantile index to be between 0 and 1\n",
    "    quantile_ranks = quantile_indices.float() / Q\n",
    "\n",
    "    # Reshape back to (C, H, W)\n",
    "    quantile_ranks = quantile_ranks.view(C, H, W)\n",
    "\n",
    "    return quantile_ranks \n",
    "\n",
    "self.model.eval()\n",
    "for batch in dataloader:\n",
    "        self.dataset = batch['Dataset']\n",
    "        input = batch['vol'][tio.DATA]\n",
    "        data_orig = batch['vol_orig'][tio.DATA]\n",
    "        data_seg = batch['seg_orig'][tio.DATA] if batch['seg_available'][0] else torch.zeros_like(data_orig)\n",
    "        data_mask = batch['mask_orig'][tio.DATA]\n",
    "        ID = batch['ID'][0]\n",
    "        age = batch['age'][0]\n",
    "        self.stage = batch['stage'][0]\n",
    "        label = batch['label'][0]\n",
    "        # self.plot_slice_error(batch)\n",
    "        start_idx = 0\n",
    "        data_seg = data_seg.squeeze(0).permute(3,0,1,2)\n",
    "        input = input.squeeze(0).permute(3,0,1,2)\n",
    "        # input = torch.from_numpy(exposure.equalize_hist(input.numpy()))\n",
    "        brain_masks = data_mask.squeeze(0).permute(3,0,1,2)\n",
    "        # Determine the number of chunks\n",
    "        num_chunks = 30 # Adjust this based on memory constraints\n",
    "        chunk_size = input.size(0) // num_chunks\n",
    "        results_error = []\n",
    "        results_logvariance = []\n",
    "        stride = (1,1,1)\n",
    "        for start in range(0, input.size(0), chunk_size):\n",
    "            # Slice the input tensor for the current chunk\n",
    "            chunk = input[start: start + chunk_size]\n",
    "\n",
    "            # Process the chunk\n",
    "            patches, locations = extract_volume_patches(chunk, self.patch_size,slice_start=start + start_idx, total_slices_num=input.shape[0],\n",
    "                                                             stride=stride,rejection_rate=self.rejection_rate)\n",
    "            with torch.no_grad():\n",
    "                predicted_locations, predicted_logvariance = self.model(patches.half().to(device), locations[:, -1].to(device))\n",
    "            predicted_locations = predicted_locations.cpu()\n",
    "            predicted_logvariance = predicted_logvariance.cpu()\n",
    "            \n",
    "            # Calculate error and reshape\n",
    "            error = torch.linalg.norm(predicted_locations - locations[:, :-1],dim=1)\n",
    "            error = self.reshape_and_upsample(error, chunk.shape, stride)\n",
    "            # error = error.reshape((input.shape[-2], input.shape[-1], input.shape[1], chunk.shape[0])).permute(3, 2, 0, 1)\n",
    "            predicted_logvariance = self.reshape_and_upsample(predicted_logvariance.mean(-1),chunk.shape, stride)\n",
    "            # predicted_logvariance = predicted_logvariance.mean(-1).reshape((input.shape[-2], input.shape[-1], input.shape[1], chunk.shape[0])).permute(3, 2, 0, 1)\n",
    "            \n",
    "            # Move results to CPU to free GPU memory\n",
    "            results_error.append(error.cpu())\n",
    "            results_logvariance.append(predicted_logvariance.cpu())\n",
    "\n",
    "        # Concatenate results from all chunks\n",
    "        error = torch.log(torch.cat(results_error, dim=0).squeeze().permute(1, 2, 0)+1e-10)\n",
    "        predicted_logvariance = torch.cat(results_logvariance, dim=0).squeeze().permute(1, 2, 0)\n",
    "\n",
    "        stats = torch.load(f\"errors_{ fold + 1}_{config['mode']}.pt\")\n",
    "        mean = stats['mean'].permute(1,2,0)\n",
    "        std = stats['std'].permute(1,2,0)\n",
    "        \n",
    "        error = (error - mean) / std\n",
    "        error = torch.nan_to_num(error, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "\n",
    "        stats = torch.load(f\"logvariances_{ fold + 1}_{config['mode']}.pt\")\n",
    "        mean = stats['mean'].permute(1,2,0)\n",
    "        std = stats['std'].permute(1,2,0)\n",
    "        \n",
    "        predicted_logvariance = (predicted_logvariance - mean) / std\n",
    "        predicted_logvariance = torch.nan_to_num(predicted_logvariance, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "                # Final computation\n",
    "        final_volume = error * predicted_logvariance\n",
    "\n",
    "        # final_volume = final_volume * get_voxel_quantile_ranks(final_volume,f\"voxel_quantiles_{fold}.pt\")\n",
    "        final_volume = final_volume.permute(2,0,1).unsqueeze(1)\n",
    "        plot_images(input, final_volume * brain_masks,data_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchio as tio\n",
    "\n",
    "from src.utils.utils import  extract_volume_patches\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Placeholder lists for features and labels\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "self.model.eval()\n",
    "stride = (self.patch_size[0],self.patch_size[1],1)\n",
    "\n",
    "for batch in dataloader:\n",
    "    input = batch['vol'][tio.DATA]\n",
    "    data_seg = batch['seg_orig'][tio.DATA] if batch['seg_available'][0] else torch.zeros_like(input)\n",
    "    brain_masks = batch['mask'][tio.DATA].squeeze(-1)\n",
    "\n",
    "    brain_masks = brain_masks.squeeze(0).permute(3, 0, 1, 2)\n",
    "    data_seg = data_seg.squeeze(0).permute(3, 0, 1, 2) > 1e-3\n",
    "    input = input.squeeze(0).permute(3, 0, 1, 2)\n",
    "\n",
    "\n",
    "    patches, _ = extract_volume_patches(input, self.patch_size, slice_start=0,\n",
    "                                        total_slices_num=input.shape[0], stride=stride,\n",
    "                                        brain_masks=brain_masks,\n",
    "                                        rejection_rate=self.rejection_rate)\n",
    "\n",
    "    patches_seg, _ = extract_volume_patches(data_seg, self.patch_size, slice_start=0,\n",
    "                                            total_slices_num=input.shape[0], stride=stride,\n",
    "                                            brain_masks=brain_masks,\n",
    "                                            rejection_rate=self.rejection_rate)\n",
    "\n",
    "    # Compute mean intensity per patch\n",
    "    mean_intensities = patches_seg.float().mean(dim=(1, 2, 3))  # Assuming (batch, H, W, D)\n",
    "\n",
    "    # Classify patches\n",
    "    mask_abnormal = mean_intensities > 0.9  # Abnormal patches\n",
    "    mask_normal = mean_intensities < 0.1    # Normal patches\n",
    "    selected_patches = mask_abnormal | mask_normal\n",
    "\n",
    "    # Keep only selected patches\n",
    "    patches = patches[selected_patches]\n",
    "    labels = mean_intensities[selected_patches].float()\n",
    "\n",
    "    if patches.size(0) > 0:  # Ensure we have valid data\n",
    "        with torch.no_grad():\n",
    "            features = self.model.encoder(patches.half().to(device))\n",
    "            all_features.append(features.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_features = np.concatenate(all_features, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "all_labels[all_labels > .9] = 1\n",
    "all_labels[all_labels < .1] = 0\n",
    "# Apply UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# reducer = TSNE(\n",
    "#     n_components=2,\n",
    "#     random_state=42,\n",
    "#     perplexity=30,         # Try reducing to 10–20 for small datasets\n",
    "#     n_iter=500,            # Reduce number of iterations (default is 1000)\n",
    "#     learning_rate='auto',  # Optional: auto adapts to data scale\n",
    "#     init='pca'             # PCA init is faster and often better\n",
    "# )\n",
    "\n",
    "\n",
    "umap_embedding = reducer.fit_transform(all_features)\n",
    "\n",
    "# Plot UMAP\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    umap_embedding[:, 0],\n",
    "    umap_embedding[:, 1],\n",
    "    c=all_labels,\n",
    "    cmap=\"coolwarm\",\n",
    "    alpha=0.5,\n",
    "    s=1  # Smaller points (default is ~20–36)\n",
    ")\n",
    "plt.colorbar(label=\"Class (0: Normal, 1: Abnormal)\")\n",
    "plt.xlabel(\"UMAP Dimension 1\")\n",
    "plt.ylabel(\"UMAP Dimension 2\")\n",
    "plt.title(\"UMAP Visualization of Extracted Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/job_30088952/step_0.0/ipykernel_23312/510662457.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0mz_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkde_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Blues\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Added contour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_error\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_0_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_logvariance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_0_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Blues\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Normal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;31m# --- Class 1 (Abnormal) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mkdeplot\u001b[0;34m(data, x, y, hue, weights, palette, hue_order, hue_norm, color, fill, multiple, common_norm, common_grid, cumulative, bw_method, bw_adjust, warn_singular, log_scale, levels, thresh, gridsize, cut, clip, legend, cbar, cbar_ax, cbar_kws, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1713\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m         p.plot_bivariate_density(\n\u001b[0m\u001b[1;32m   1716\u001b[0m             \u001b[0mcommon_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommon_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m             \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mplot_bivariate_density\u001b[0;34m(self, common_norm, fill, levels, thresh, color, legend, cbar, warn_singular, cbar_ax, cbar_kws, estimate_kws, **contour_kws)\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msingular\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m                     \u001b[0mdensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0;31m# Testing for 0 variance doesn't catch all cases where scipy raises,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/seaborn/_statistics.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, weights)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_univariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_bivariate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/seaborn/_statistics.py\u001b[0m in \u001b[0;36m_eval_bivariate\u001b[0;34m(self, x1, x2, weights)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mxx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mdensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/cniel/.conda/cvpr/lib/python3.9/site-packages/scipy/stats/kde.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m    250\u001b[0m             raise TypeError('%s has unexpected item size %d' %\n\u001b[1;32m    251\u001b[0m                             (output_dtype, itemsize))\n\u001b[0;32m--> 252\u001b[0;31m         result = gaussian_kernel_estimate[spec](self.dataset.T, self.weights[:, None],\n\u001b[0m\u001b[1;32m    253\u001b[0m                                                 points.T, self.inv_cov, output_dtype)\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torchio as tio\n",
    "\n",
    "from src.utils.utils import  extract_volume_patches\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "self.model.eval()\n",
    "stride = (self.patch_size[0],self.patch_size[1],1)\n",
    "for stage in [0,1]:\n",
    "    results_logvariance = []\n",
    "    results_error = []\n",
    "    results_label = []\n",
    "\n",
    "    logerror_stats = torch.load(f\"errors_{ fold + 1}_{config['mode']}.pt\")\n",
    "    logerror_mean = logerror_stats['mean'].unsqueeze(1)\n",
    "    logerror_std = logerror_stats['std'].unsqueeze(1)\n",
    "\n",
    "    logvariance_stats = torch.load(f\"logvariances_{ fold + 1}_{config['mode']}.pt\")\n",
    "    logvariance_mean = logvariance_stats['mean'].unsqueeze(1)\n",
    "    logvariance_std = logvariance_stats['std'].unsqueeze(1)\n",
    "\n",
    "    def get_refereces(brain_masks):\n",
    "        logvariance_mean_ref, _ = extract_volume_patches(logvariance_mean, self.patch_size, slice_start=0,\n",
    "                                                    total_slices_num=logvariance_mean.shape[0], stride=stride,\n",
    "                                                    rejection_rate=self.rejection_rate,\n",
    "                                                    brain_masks=brain_masks)\n",
    "        logvariance_std_ref, _ = extract_volume_patches(logvariance_std, self.patch_size, slice_start=0,\n",
    "                                                    total_slices_num=logvariance_mean.shape[0], stride=stride,\n",
    "                                                    rejection_rate=self.rejection_rate,\n",
    "                                                    brain_masks=brain_masks)\n",
    "        logerror_mean_ref, _ = extract_volume_patches(logerror_mean, self.patch_size, slice_start=0,\n",
    "                                                    total_slices_num=logvariance_mean.shape[0], stride=stride,\n",
    "                                                    rejection_rate=self.rejection_rate,\n",
    "                                                    brain_masks=brain_masks)\n",
    "        logerror_std_ref, _ = extract_volume_patches(logerror_std, self.patch_size, slice_start=0,\n",
    "                                                    total_slices_num=logvariance_mean.shape[0], stride=stride,\n",
    "                                                    rejection_rate=self.rejection_rate,\n",
    "                                                    brain_masks=brain_masks)\n",
    "        \n",
    "        logvariance_mean_ref = logvariance_mean_ref.numpy().mean(axis=(-1,-2)).squeeze()\n",
    "        logvariance_std_ref = logvariance_std_ref.numpy().mean(axis=(-1,-2)).squeeze()\n",
    "        logerror_mean_ref = logerror_mean_ref.numpy().mean(axis=(-1,-2)).squeeze()\n",
    "        logerror_std_ref = logerror_std_ref.numpy().mean(axis=(-1,-2)).squeeze()\n",
    "        return logvariance_mean_ref, logvariance_std_ref, logerror_mean_ref, logerror_std_ref\n",
    "\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input = batch['vol'][tio.DATA]\n",
    "        data_seg = batch['seg_orig'][tio.DATA] if batch['seg_available'][0] else torch.zeros_like(input)\n",
    "        brain_masks = batch['mask'][tio.DATA].squeeze(-1)\n",
    "\n",
    "        brain_masks = brain_masks.squeeze(0).permute(3, 0, 1, 2)\n",
    "        data_seg = data_seg.squeeze(0).permute(3, 0, 1, 2) > 1e-3\n",
    "        input = input.squeeze(0).permute(3, 0, 1, 2)\n",
    "\n",
    "        patches, locations = extract_volume_patches(input, self.patch_size, slice_start=0,\n",
    "                                            total_slices_num=input.shape[0], stride=stride,\n",
    "                                            rejection_rate=self.rejection_rate,brain_masks=brain_masks)\n",
    "\n",
    "        patches_seg, _ = extract_volume_patches(data_seg, self.patch_size, slice_start=0,\n",
    "                                                total_slices_num=input.shape[0], stride=stride,\n",
    "                                                rejection_rate=self.rejection_rate,brain_masks=brain_masks)\n",
    "\n",
    "        # Compute mean intensity per patch\n",
    "        mean_intensities = patches_seg.float().mean(dim=(1, 2, 3))  # Assuming (batch, H, W, D)\n",
    "\n",
    "        # Classify patches\n",
    "        mask_abnormal = mean_intensities > 0.9  # Abnormal patches\n",
    "        mask_normal = mean_intensities < 0.1    # Normal patches\n",
    "        selected_patches = mask_abnormal | mask_normal\n",
    "\n",
    "        # Keep only selected patches\n",
    "        patches = patches[selected_patches]\n",
    "        locations = locations[selected_patches]\n",
    "        labels = mean_intensities[selected_patches] \n",
    "        results_label.append(labels.cpu().numpy())\n",
    "\n",
    "        if stage == 1:\n",
    "             logvariance_mean_ref, logvariance_std_ref, logerror_mean_ref, logerror_std_ref = get_refereces(brain_masks)\n",
    "        if patches.size(0) > 0:  # Ensure we have valid data\n",
    "            with torch.no_grad():\n",
    "                predicted_locations, predicted_logvariance = self.model(patches.half().to(device),locations[:,-1])\n",
    "\n",
    "                predicted_locations = predicted_locations.cpu()\n",
    "                predicted_logvariance = predicted_logvariance.cpu().mean(-1)\n",
    "\n",
    "                error = torch.linalg.norm(predicted_locations - locations[:, :-1],dim=1)\n",
    "                log_error = np.log(error.cpu().numpy() + 1e-6)\n",
    "\n",
    "                if stage == 1:\n",
    "                            log_error = (log_error - logerror_mean_ref[selected_patches]) / logerror_std_ref[selected_patches]\n",
    "                            log_error = np.nan_to_num(log_error, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                            predicted_logvariance = (predicted_logvariance - logvariance_mean_ref[selected_patches]) / logvariance_std_ref[selected_patches]\n",
    "                            predicted_logvariance = np.nan_to_num(predicted_logvariance, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                results_error.append(log_error)\n",
    "                results_logvariance.append(predicted_logvariance)\n",
    "\n",
    "\n",
    "\n",
    "    results_label = np.concatenate(results_label, axis=0)\n",
    "    results_error = np.concatenate(results_error, axis=0)\n",
    "    results_logvariance = np.concatenate(results_logvariance, axis=0)\n",
    "\n",
    "    results_label[results_label > .9] = 1\n",
    "    results_label[results_label < .1] = 0\n",
    "    # Compute Gaussian KL divergence: KL(N0 || N1)\n",
    "    # Where N0 ~ (mean_error, var_error), N1 ~ (mean_logvar, var_logvar)\n",
    "    mean_error = np.mean(results_error)\n",
    "    var_error = np.var(results_error)\n",
    "\n",
    "    mean_logvar = np.mean(results_logvariance)\n",
    "    var_logvar = np.var(results_logvariance)\n",
    "\n",
    "    # KL divergence between two univariate Gaussians\n",
    "    def kl_gaussian(mu0, var0, mu1, var1):\n",
    "        return 0.5 * (np.log(var1 / var0) + (var0 + (mu0 - mu1)**2) / var1 - 1)\n",
    "\n",
    "    kl_div = kl_gaussian(mean_error, var_error, mean_logvar, var_logvar)\n",
    "\n",
    "    # Prepare data for KDE plots\n",
    "    class_0_idx = results_label == 0\n",
    "    class_1_idx = results_label == 1\n",
    "\n",
    "\n",
    "    # Create KDE plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # results_error = np.clip(results_error,np.quantile(results_error,.02),np.quantile(results_error,.90))\n",
    "    # results_logvariance = np.clip(results_logvariance,np.quantile(results_logvariance,.02),np.quantile(results_logvariance,.90))\n",
    "    sns.kdeplot(x=results_error[class_0_idx], y=results_logvariance[class_0_idx], cmap=\"Blues\", fill=False, label=\"Normal\",alpha=.5)\n",
    "    sns.kdeplot(x=results_error[class_1_idx], y=results_logvariance[class_1_idx], cmap=\"Reds\", fill=False, label=\"Abnormal\",alpha=.5)\n",
    "    plt.xlabel(\"Log Error\")\n",
    "    plt.ylabel(\"Log Variance\")\n",
    "    conditional_stage = 'z-normalized' if stage == 1 else ''\n",
    "    plt.title(f\"2D KDE Plot of Log Error vs Log Variance\\nKL Divergence: {kl_div:.4f}, {conditional_stage}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
